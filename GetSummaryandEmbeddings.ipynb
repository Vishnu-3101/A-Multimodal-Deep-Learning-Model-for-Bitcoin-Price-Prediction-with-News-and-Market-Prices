{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-26T06:53:24.931880Z",
     "iopub.status.busy": "2024-04-26T06:53:24.931416Z",
     "iopub.status.idle": "2024-04-26T06:53:24.937991Z",
     "shell.execute_reply": "2024-04-26T06:53:24.936562Z",
     "shell.execute_reply.started": "2024-04-26T06:53:24.931847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T05:15:07.970160Z",
     "iopub.status.busy": "2024-04-26T05:15:07.969447Z",
     "iopub.status.idle": "2024-04-26T05:15:28.720515Z",
     "shell.execute_reply": "2024-04-26T05:15:28.719067Z",
     "shell.execute_reply.started": "2024-04-26T05:15:07.970111Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=6bbb9b7f4a23b9e15cf8505d1e46419928c9916e43ccd5afdb9f498d5df161bb\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T06:45:20.987808Z",
     "iopub.status.busy": "2024-04-26T06:45:20.986586Z",
     "iopub.status.idle": "2024-04-26T06:45:36.315407Z",
     "shell.execute_reply": "2024-04-26T06:45:36.313704Z",
     "shell.execute_reply.started": "2024-04-26T06:45:20.987760Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.23.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "from openai import OpenAI\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T06:55:56.253486Z",
     "iopub.status.busy": "2024-04-26T06:55:56.253023Z",
     "iopub.status.idle": "2024-04-26T06:55:56.277770Z",
     "shell.execute_reply": "2024-04-26T06:55:56.276296Z",
     "shell.execute_reply.started": "2024-04-26T06:55:56.253454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,df_path,verbose = False):\n",
    "        self.df = pd.read_csv(df_path)\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def group_three_words(self):\n",
    "        def three_words(text):\n",
    "            return text.split()[0:3]\n",
    "        self.df['Text'] = self.df['Text'].apply(lambda x:' '.join(x.splitlines()))\n",
    "        first_three_df = self.df\n",
    "        if(self.verbose):\n",
    "            print(\"Grouping the 1st three words in each text.......\")\n",
    "        first_three_df['first_three_words'] = first_three_df['Text'].apply(three_words)\n",
    "        first_three_df = self.df.loc[lambda first_three_df:first_three_df['Text']!='']\n",
    "        first_three_df.drop_duplicates(subset= 'first_three_words',keep='first',inplace=True)\n",
    "        if(self.verbose):\n",
    "            print(\"Done with Grouping the 1st three words in each text!!!\")\n",
    "        return first_three_df\n",
    "        \n",
    "        \n",
    "    def extract_eng_text(self,df):\n",
    "        def detectLang(text):\n",
    "            try:\n",
    "                lang = detect(text)\n",
    "                return lang == 'en' \n",
    "            except:\n",
    "                return False\n",
    "        if(self.verbose):\n",
    "            print(\"Checking for english text........\")\n",
    "        df['english'] = df['Text'].apply(detectLang)\n",
    "        df = df[df['english']]\n",
    "        if(self.verbose):\n",
    "            print(\"None English text removed!!!!\")\n",
    "        return df[['time','Text','Link']]\n",
    "    \n",
    "    def group_hour_data(self):\n",
    "        def remove_urls(text):\n",
    "            url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "            return re.sub(url_pattern, '', text)\n",
    "        \n",
    "        three_words = self.group_three_words()\n",
    "        self.processed_data = self.extract_eng_text(three_words)\n",
    "        self.processed_data['Text'] = self.processed_data['Text'].map(remove_urls)\n",
    "        self.processed_data['time'] = pd.to_datetime(self.processed_data['time'])\n",
    "        self.processed_data.sort_values(by=\"time\",na_position=\"first\",inplace = True)\n",
    "        if(self.verbose):\n",
    "            print(\"Strating the process of grouping the text by hour.......\")\n",
    "        self.processed_data['hour_data'] = self.processed_data['time'].dt.hour\n",
    "        self.before_group = self.processed_data\n",
    "        self.processed_data = self.processed_data.groupby([self.processed_data['time'].dt.date,self.processed_data['hour_data']])['Text'].agg(lambda x: ' '.join(x)).reset_index()\n",
    "        if(self.verbose):\n",
    "            print(\"Done with preprocessing!!!\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def fill_missing_hours(self):\n",
    "        grouped_data = self.processed_data\n",
    "        grouped_data['time'] = pd.to_datetime(grouped_data['time'])\n",
    "        grouped_data['hour_data'] = grouped_data['hour_data'].astype(int)\n",
    "        grouped_data['full_time'] = grouped_data['time'] + pd.to_timedelta(grouped_data['hour_data'], unit='h')\n",
    "        date_range = pd.date_range(start='2023-01-01', end='2023-01-31 23:00:00', freq='h')\n",
    "        all_hours_df = pd.DataFrame(date_range, columns=['full_time'])\n",
    "        merged_df = pd.merge(all_hours_df[['full_time']], grouped_data[['full_time', 'Text']], on='full_time', how='left')\n",
    "        merged_df['Text'] = merged_df['Text'].ffill()\n",
    "        return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T06:55:56.648711Z",
     "iopub.status.busy": "2024-04-26T06:55:56.648245Z",
     "iopub.status.idle": "2024-04-26T06:56:57.870077Z",
     "shell.execute_reply": "2024-04-26T06:56:57.868776Z",
     "shell.execute_reply.started": "2024-04-26T06:55:56.648678Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping the 1st three words in each text.......\n",
      "Done with Grouping the 1st three words in each text!!!\n",
      "Checking for english text........\n",
      "None English text removed!!!!\n",
      "Strating the process of grouping the text by hour.......\n",
      "Done with preprocessing!!!\n"
     ]
    }
   ],
   "source": [
    "df_path = \"/kaggle/input/jan-2023-raw/jan_2023.csv\"\n",
    "df = Dataset(df_path,verbose=True)\n",
    "final_data = df.group_hour_data().fill_missing_hours()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T06:54:47.848528Z",
     "iopub.status.busy": "2024-04-26T06:54:47.848041Z",
     "iopub.status.idle": "2024-04-26T06:54:47.930895Z",
     "shell.execute_reply": "2024-04-26T06:54:47.929675Z",
     "shell.execute_reply.started": "2024-04-26T06:54:47.848490Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_data.to_csv(\"/kaggle/working/2023_jan(3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T07:37:22.150738Z",
     "iopub.status.busy": "2024-04-26T07:37:22.150186Z",
     "iopub.status.idle": "2024-04-26T07:37:22.162379Z",
     "shell.execute_reply": "2024-04-26T07:37:22.160932Z",
     "shell.execute_reply.started": "2024-04-26T07:37:22.150700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Openai:\n",
    "    def __init__(self,dataset):\n",
    "        self.data = dataset\n",
    "    \n",
    "    def get_text_summary(self,start,end):\n",
    "        processed_data = self.data.iloc[start:end].reset_index()\n",
    "        client = OpenAI(\n",
    "          api_key=\"YOUR_API_KEY\"\n",
    "        )\n",
    "        model = \"gpt-3.5-turbo\"\n",
    "        content = \"You are a very good text summarizer for bitcoin related news helping in accurate price prediction in 150 words\"\n",
    "        \n",
    "        for i,t in enumerate(tqdm(processed_data['Text'])):\n",
    "            text = str(processed_data.loc[i,'Text'])\n",
    "            try: \n",
    "                completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": content},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                  ]\n",
    "                )\n",
    "            except:\n",
    "                print(i)\n",
    "            processed_data.loc[i,'Summarized_text'] = str(completion.choices[0].message.content)\n",
    "        return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T07:37:58.992880Z",
     "iopub.status.busy": "2024-04-26T07:37:58.992380Z",
     "iopub.status.idle": "2024-04-26T08:10:35.057946Z",
     "shell.execute_reply": "2024-04-26T08:10:35.056686Z",
     "shell.execute_reply.started": "2024-04-26T07:37:58.992842Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [32:36<00:00, 19.56s/it]\n"
     ]
    }
   ],
   "source": [
    "oa = Openai(final_data)\n",
    "processed_data = oa.get_text_summary(100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T08:11:41.567989Z",
     "iopub.status.busy": "2024-04-26T08:11:41.567487Z",
     "iopub.status.idle": "2024-04-26T08:11:41.591356Z",
     "shell.execute_reply": "2024-04-26T08:11:41.589847Z",
     "shell.execute_reply.started": "2024-04-26T08:11:41.567954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processed_data.to_csv(\"/kaggle/working/2023_jan_summarized_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:45:31.724416Z",
     "iopub.status.busy": "2024-04-26T09:45:31.723970Z",
     "iopub.status.idle": "2024-04-26T09:45:31.744676Z",
     "shell.execute_reply": "2024-04-26T09:45:31.743447Z",
     "shell.execute_reply.started": "2024-04-26T09:45:31.724386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "client = OpenAI(\n",
    "  api_key=\"YOUR_API_KEY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-19T06:42:45.479995Z",
     "iopub.status.busy": "2024-04-19T06:42:45.479248Z",
     "iopub.status.idle": "2024-04-19T06:42:45.507811Z",
     "shell.execute_reply": "2024-04-19T06:42:45.506784Z",
     "shell.execute_reply.started": "2024-04-19T06:42:45.479961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# train_df = pd.read_csv(\"/kaggle/input/train-test-2021-jul/text_train.csv\")\n",
    "# test_df = pd.read_csv(\"/kaggle/input/train-test-2021-jul/text_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:45:37.570742Z",
     "iopub.status.busy": "2024-04-26T09:45:37.570228Z",
     "iopub.status.idle": "2024-04-26T09:45:37.577124Z",
     "shell.execute_reply": "2024-04-26T09:45:37.575950Z",
     "shell.execute_reply.started": "2024-04-26T09:45:37.570704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   time.sleep(20)\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T08:51:24.472136Z",
     "iopub.status.busy": "2024-04-26T08:51:24.471177Z",
     "iopub.status.idle": "2024-04-26T09:24:12.169241Z",
     "shell.execute_reply": "2024-04-26T09:24:12.167891Z",
     "shell.execute_reply.started": "2024-04-26T08:51:24.472098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processed_data['ada_embedding'] = processed_data['Summarized_text'].apply(lambda x: get_embedding(x, model='text-embedding-3-small'))\n",
    "processed_data.to_csv('/kaggle/working/jan_2023_embedded_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:45:42.336824Z",
     "iopub.status.busy": "2024-04-26T09:45:42.336333Z",
     "iopub.status.idle": "2024-04-26T09:45:42.353902Z",
     "shell.execute_reply": "2024-04-26T09:45:42.352611Z",
     "shell.execute_reply.started": "2024-04-26T09:45:42.336773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processed_data2 = pd.read_csv(\"/kaggle/working/2023_jan_summarized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-26T09:45:43.164832Z",
     "iopub.status.busy": "2024-04-26T09:45:43.164358Z",
     "iopub.status.idle": "2024-04-26T10:19:39.787375Z",
     "shell.execute_reply": "2024-04-26T10:19:39.786118Z",
     "shell.execute_reply.started": "2024-04-26T09:45:43.164790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processed_data2['ada_embedding'] = processed_data2['Summarized_text'].apply(lambda x: get_embedding(x, model='text-embedding-3-small'))\n",
    "processed_data2.to_csv('/kaggle/working/jan_2023_embedded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4752029,
     "sourceId": 8056833,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4819870,
     "sourceId": 8149782,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4829334,
     "sourceId": 8162332,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4875703,
     "sourceId": 8223712,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
